# Trustpilot Sentiment Classification - MLOps Case

This repository contains a complete ML pipeline for a sentiment classification system trained on Amazon book reviews. The project was completed as part of a take-home interview case and includes data preprocessing, model training using Hugging Face Transformers, API deployment via FastAPI, experiment tracking with MLflow, testing, and Dockerization.

---

## ğŸ“ Project Structure

```
amazon-sentiment-mlops-tpilot/
.
â”œâ”€â”€ app/                      # Application code
â”‚   â”œâ”€â”€ api.py               # FastAPI server and endpoint
â”‚   â”œâ”€â”€ preprocess.py        # Separate .py file for preprocessing functions
â”‚   â”œâ”€â”€ test_inference_latency.py   # API latency test for case purposes
â”‚   â””â”€â”€ train.py             # Model training pipeline
â”‚
â”œâ”€â”€ tests/                   # Unit tests
â”‚   â”œâ”€â”€ test_api.py
â”‚   â””â”€â”€ test_preprocessing.py
â”‚
â”œâ”€â”€ data/                    # Raw data, processed data and holdout samples
â”‚   â”œâ”€â”€ Books_10k.jsonl      # raw
â”‚   â”œâ”€â”€ processed_reviews.csv  # processed
â”‚   â””â”€â”€ inference_holdout_raw.json  # holdout
â”‚
â”œâ”€â”€ .github/workflows/        # CI test
â”‚   â””â”€â”€ test.yml
â”‚
â”œâ”€â”€ notebooks/        # Jupyter Notebooks
â”‚   â””â”€â”€ data_exploration_and_prepration.ipynb
â”‚
â”œâ”€â”€ upload_to_hf.py          # Script to upload model to Hugging Face
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ Dockerfile               # Container config
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


```
---

## Setup Instructions

### 1. Environment Setup

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. Prepare Data
Navigate to the notebooks/ folder and launch Jupyter:

```bash
cd notebooks
jupyter notebook
```
Open `data_exploration_and_prepration.ipynb` and run it to have the preprocessed and clean data ready for training.

### 3. Train the Model

Run training with the desired number of epochs:

```bash
python app/train.py --epochs 3
python app/train.py --epochs 5
```

Artifacts:

- Model and tokenizer saved locally under `model_{epochs}epochs/` (will be created after training the model to save it locally)
- MLflow logs stored in `mlruns/` (will be auto-generated by MLflow; tracks experiment parameters, metrics, and artifacts for experiment reproducibility)
- Hugging Face training outputs saved in `outputs_{epochs}epochs/` (will be created automatically by Hugging Face's Trainer; contains checkpoints, optimizer states, and logs for each epoch)
- Saving structured output logs in `logs/` (will be auto-generated, configured in logging.basicConfig(). in api.py) 

### 4. Run the API Server using uvicorn

```bash
uvicorn app.api:app --reload
```

Then, send a POST request to `http://127.0.0.1:8000/predict` with:

```json
{
  "text": "This book was fantastic!"
}
```
or using `httpie`

```bash
http POST http://127.0.0.1:8000/predict text="This book was fantastic!"
```

### 5. Measure API Latency

```bash
python app/test_inference_latency.py
```
---

## Testing
**Test Suite** for preprocessing logic and endpoint testing
Run unit tests:

```bash
pytest tests/test_api.py
pytest tests/test_preprocessing.py
```
---

## Monitoring
**MLflow Tracking** for reproducible training and comparison across runs
Monitor the training and the models using `mlflow`:

```bash
mlflow ui
```
---

## Containerization
**Docker Support** for portable deployment
Use docker to containerize the project:
The API will download the model from Hugging Face on the first run (no manual upload needed).

```bash
docker build -t sentiment-api .
docker run -p 8000:8000 sentiment-api
```
---

## CI Workflow
This repo includes a CI workflow in `.github/workflows/test.yml`, which automatically runs all unit tests on push.

---

## Model Info

- Base model: `distilbert-base-uncased`
- Fine-tuned on labeled Amazon book reviews
- 3 sentiment classes: positive, neutral, negative
- Hosted at: https://huggingface.co/MiladMt/sentiment-api-model

## Upoload your model to Hugginface
To upload your trained model to hf, use:

```bash
python upload_to_hf.py
```

---

## Disclaimer

This project was developed as part of a take-home technical case for Trustpilot.  
All rights to the original case description and business context belong to Trustpilot.  
This repository is shared solely for review purposes and not intended for public or commercial use.
